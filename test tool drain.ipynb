{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fdaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff216f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logcluster:\n",
    "    def __init__(self, logTemplate='', logIDL=None):\n",
    "        self.logTemplate = logTemplate\n",
    "        if logIDL is None:\n",
    "            logIDL = []\n",
    "        self.logIDL = logIDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb41387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, childD=None, depth=0, digitOrtoken=None):\n",
    "        if childD is None:\n",
    "            childD = dict()\n",
    "        self.childD = childD\n",
    "        self.depth = depth\n",
    "        self.digitOrtoken = digitOrtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a8031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogParser:\n",
    "    def __init__(self, log_format, indir='./', outdir='./result/', depth=4, st=0.4, \n",
    "                 maxChild=100, rex=[], keep_para=True):\n",
    "        \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "            rex : regular expressions used in preprocessing (step1)\n",
    "            path : the input path stores the input log file name\n",
    "            depth : depth of all leaf nodes\n",
    "            st : similarity threshold\n",
    "            maxChild : max number of children of an internal node\n",
    "            logName : the name of the input file containing raw log messages\n",
    "            savePath : the output path stores the file containing structured logs\n",
    "        \"\"\"\n",
    "        self.path = indir\n",
    "        self.depth = depth - 2\n",
    "        self.st = st\n",
    "        self.maxChild = maxChild\n",
    "        self.logName = None\n",
    "        self.savePath = outdir\n",
    "        self.df_log = None\n",
    "        self.log_format = log_format\n",
    "        self.rex = rex\n",
    "        self.keep_para = keep_para\n",
    "\n",
    "    def hasNumbers(self, s):\n",
    "        return any(char.isdigit() for char in s)\n",
    "\n",
    "    def treeSearch(self, rn, seq):\n",
    "        retLogClust = None\n",
    "\n",
    "        seqLen = len(seq)\n",
    "        if seqLen not in rn.childD:\n",
    "            return retLogClust\n",
    "\n",
    "        parentn = rn.childD[seqLen]\n",
    "\n",
    "        currentDepth = 1\n",
    "        for token in seq:\n",
    "            if currentDepth >= self.depth or currentDepth > seqLen:\n",
    "                break\n",
    "\n",
    "            if token in parentn.childD:\n",
    "                parentn = parentn.childD[token]\n",
    "            elif '<*>' in parentn.childD:\n",
    "                parentn = parentn.childD['<*>']\n",
    "            else:\n",
    "                return retLogClust\n",
    "            currentDepth += 1\n",
    "\n",
    "        logClustL = parentn.childD\n",
    "\n",
    "        retLogClust = self.fastMatch(logClustL, seq)\n",
    "\n",
    "        return retLogClust\n",
    "\n",
    "    def addSeqToPrefixTree(self, rn, logClust):\n",
    "        seqLen = len(logClust.logTemplate)\n",
    "        if seqLen not in rn.childD:\n",
    "            firtLayerNode = Node(depth=1, digitOrtoken=seqLen)\n",
    "            rn.childD[seqLen] = firtLayerNode\n",
    "        else:\n",
    "            firtLayerNode = rn.childD[seqLen]\n",
    "\n",
    "        parentn = firtLayerNode\n",
    "\n",
    "        currentDepth = 1\n",
    "        for token in logClust.logTemplate:\n",
    "\n",
    "            #Add current log cluster to the leaf node\n",
    "            if currentDepth >= self.depth or currentDepth > seqLen:\n",
    "                if len(parentn.childD) == 0:\n",
    "                    parentn.childD = [logClust]\n",
    "                else:\n",
    "                    parentn.childD.append(logClust)\n",
    "                break\n",
    "\n",
    "            #If token not matched in this layer of existing tree. \n",
    "            if token not in parentn.childD:\n",
    "                if not self.hasNumbers(token):\n",
    "                    if '<*>' in parentn.childD:\n",
    "                        if len(parentn.childD) < self.maxChild:\n",
    "                            newNode = Node(depth=currentDepth + 1, digitOrtoken=token)\n",
    "                            parentn.childD[token] = newNode\n",
    "                            parentn = newNode\n",
    "                        else:\n",
    "                            parentn = parentn.childD['<*>']\n",
    "                    else:\n",
    "                        if len(parentn.childD)+1 < self.maxChild:\n",
    "                            newNode = Node(depth=currentDepth+1, digitOrtoken=token)\n",
    "                            parentn.childD[token] = newNode\n",
    "                            parentn = newNode\n",
    "                        elif len(parentn.childD)+1 == self.maxChild:\n",
    "                            newNode = Node(depth=currentDepth+1, digitOrtoken='<*>')\n",
    "                            parentn.childD['<*>'] = newNode\n",
    "                            parentn = newNode\n",
    "                        else:\n",
    "                            parentn = parentn.childD['<*>']\n",
    "            \n",
    "                else:\n",
    "                    if '<*>' not in parentn.childD:\n",
    "                        newNode = Node(depth=currentDepth+1, digitOrtoken='<*>')\n",
    "                        parentn.childD['<*>'] = newNode\n",
    "                        parentn = newNode\n",
    "                    else:\n",
    "                        parentn = parentn.childD['<*>']\n",
    "\n",
    "            #If the token is matched\n",
    "            else:\n",
    "                parentn = parentn.childD[token]\n",
    "\n",
    "            currentDepth += 1\n",
    "\n",
    "    #seq1 is template\n",
    "    def seqDist(self, seq1, seq2):\n",
    "        assert len(seq1) == len(seq2)\n",
    "        simTokens = 0\n",
    "        numOfPar = 0\n",
    "\n",
    "        for token1, token2 in zip(seq1, seq2):\n",
    "            if token1 == '<*>':\n",
    "                numOfPar += 1\n",
    "                continue\n",
    "            if token1 == token2:\n",
    "                simTokens += 1 \n",
    "\n",
    "        retVal = float(simTokens) / len(seq1)\n",
    "\n",
    "        return retVal, numOfPar\n",
    "\n",
    "\n",
    "    def fastMatch(self, logClustL, seq):\n",
    "        retLogClust = None\n",
    "\n",
    "        maxSim = -1\n",
    "        maxNumOfPara = -1\n",
    "        maxClust = None\n",
    "\n",
    "        for logClust in logClustL:\n",
    "            curSim, curNumOfPara = self.seqDist(logClust.logTemplate, seq)\n",
    "            if curSim>maxSim or (curSim==maxSim and curNumOfPara>maxNumOfPara):\n",
    "                maxSim = curSim\n",
    "                maxNumOfPara = curNumOfPara\n",
    "                maxClust = logClust\n",
    "\n",
    "        if maxSim >= self.st:\n",
    "            retLogClust = maxClust  \n",
    "\n",
    "        return retLogClust\n",
    "\n",
    "    def getTemplate(self, seq1, seq2):\n",
    "        assert len(seq1) == len(seq2)\n",
    "        retVal = []\n",
    "\n",
    "        i = 0\n",
    "        for word in seq1:\n",
    "            if word == seq2[i]:\n",
    "                retVal.append(word)\n",
    "            else:\n",
    "                retVal.append('<*>')\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return retVal\n",
    "\n",
    "    def outputResult(self, logClustL):\n",
    "        log_templates = [0] * self.df_log.shape[0]\n",
    "        log_templateids = [0] * self.df_log.shape[0]\n",
    "        df_events = []\n",
    "        for logClust in logClustL:\n",
    "            template_str = ' '.join(logClust.logTemplate)\n",
    "            occurrence = len(logClust.logIDL)\n",
    "            template_id = hashlib.md5(template_str.encode('utf-8')).hexdigest()[0:8]\n",
    "            for logID in logClust.logIDL:\n",
    "                logID -= 1\n",
    "                log_templates[logID] = template_str\n",
    "                log_templateids[logID] = template_id\n",
    "            df_events.append([template_id, template_str, occurrence])\n",
    "\n",
    "        df_event = pd.DataFrame(df_events, columns=['EventId', 'EventTemplate', 'Occurrences'])\n",
    "        self.df_log['EventId'] = log_templateids\n",
    "        self.df_log['EventTemplate'] = log_templates\n",
    "\n",
    "        if self.keep_para:\n",
    "            self.df_log[\"ParameterList\"] = self.df_log.apply(self.get_parameter_list, axis=1) \n",
    "        self.df_log.to_csv(os.path.join(self.savePath, self.logName + '_structured.csv'), index=False)\n",
    "\n",
    "\n",
    "        occ_dict = dict(self.df_log['EventTemplate'].value_counts())\n",
    "        df_event = pd.DataFrame()\n",
    "        df_event['EventTemplate'] = self.df_log['EventTemplate'].unique()\n",
    "        df_event['EventId'] = df_event['EventTemplate'].map(lambda x: hashlib.md5(x.encode('utf-8')).hexdigest()[0:8])\n",
    "        df_event['Occurrences'] = df_event['EventTemplate'].map(occ_dict)\n",
    "        df_event.to_csv(os.path.join(self.savePath, self.logName + '_templates.csv'), index=False, columns=[\"EventId\", \"EventTemplate\", \"Occurrences\"])\n",
    "\n",
    "\n",
    "    def printTree(self, node, dep):\n",
    "        pStr = ''   \n",
    "        for i in range(dep):\n",
    "            pStr += '\\t'\n",
    "\n",
    "        if node.depth == 0:\n",
    "            pStr += 'Root'\n",
    "        elif node.depth == 1:\n",
    "            pStr += '<' + str(node.digitOrtoken) + '>'\n",
    "        else:\n",
    "            pStr += node.digitOrtoken\n",
    "\n",
    "        print(pStr)\n",
    "\n",
    "        if node.depth == self.depth:\n",
    "            return 1\n",
    "        for child in node.childD:\n",
    "            self.printTree(node.childD[child], dep+1)\n",
    "\n",
    "\n",
    "    def parse(self, logName):\n",
    "        print('Parsing file: ' + os.path.join(self.path, logName))\n",
    "        start_time = datetime.now()\n",
    "        self.logName = logName\n",
    "        rootNode = Node()\n",
    "        logCluL = []\n",
    "\n",
    "        self.load_data()\n",
    "\n",
    "        count = 0\n",
    "        for idx, line in self.df_log.iterrows():\n",
    "            logID = line['LineId']\n",
    "            logmessageL = self.preprocess(line['Content']).strip().split()\n",
    "            # logmessageL = filter(lambda x: x != '', re.split('[\\s=:,]', self.preprocess(line['Content'])))\n",
    "            matchCluster = self.treeSearch(rootNode, logmessageL)\n",
    "\n",
    "            #Match no existing log cluster\n",
    "            if matchCluster is None:\n",
    "                newCluster = Logcluster(logTemplate=logmessageL, logIDL=[logID])\n",
    "                logCluL.append(newCluster)\n",
    "                self.addSeqToPrefixTree(rootNode, newCluster)\n",
    "\n",
    "            #Add the new log message to the existing cluster\n",
    "            else:\n",
    "                newTemplate = self.getTemplate(logmessageL, matchCluster.logTemplate)\n",
    "                matchCluster.logIDL.append(logID)\n",
    "                if ' '.join(newTemplate) != ' '.join(matchCluster.logTemplate): \n",
    "                    matchCluster.logTemplate = newTemplate\n",
    "\n",
    "            count += 1\n",
    "            if count % 1000 == 0 or count == len(self.df_log):\n",
    "                print('Processed {0:.1f}% of log lines.'.format(count * 100.0 / len(self.df_log)))\n",
    "\n",
    "\n",
    "        if not os.path.exists(self.savePath):\n",
    "            os.makedirs(self.savePath)\n",
    "\n",
    "        self.outputResult(logCluL)\n",
    "\n",
    "        print('Parsing done. [Time taken: {!s}]'.format(datetime.now() - start_time))\n",
    "\n",
    "    def load_data(self):\n",
    "        headers, regex = self.generate_logformat_regex(self.log_format)\n",
    "        self.df_log = self.log_to_dataframe(os.path.join(self.path, self.logName), regex, headers, self.log_format)\n",
    "\n",
    "    def preprocess(self, line):\n",
    "        for currentRex in self.rex:\n",
    "            line = re.sub(currentRex, '<*>', line)\n",
    "        return line\n",
    "\n",
    "    def log_to_dataframe(self, log_file, regex, headers, logformat):\n",
    "        \"\"\" Function to transform log file to dataframe \n",
    "        \"\"\"\n",
    "        log_messages = []\n",
    "        linecount = 0\n",
    "        with open(log_file, 'r') as fin:\n",
    "            for line in fin.readlines():\n",
    "                try:\n",
    "                    match = regex.search(line.strip())\n",
    "                    message = [match.group(header) for header in headers]\n",
    "                    log_messages.append(message)\n",
    "                    linecount += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        logdf = pd.DataFrame(log_messages, columns=headers)\n",
    "        logdf.insert(0, 'LineId', None)\n",
    "        logdf['LineId'] = [i + 1 for i in range(linecount)]\n",
    "        return logdf\n",
    "\n",
    "\n",
    "    def generate_logformat_regex(self, logformat):\n",
    "        \"\"\" Function to generate regular expression to split log messages\n",
    "        \"\"\"\n",
    "        headers = []\n",
    "        splitters = re.split(r'(<[^<>]+>)', logformat)\n",
    "        regex = ''\n",
    "        for k in range(len(splitters)):\n",
    "            if k % 2 == 0:\n",
    "                splitter = re.sub(' +', '\\\\\\s+', splitters[k])\n",
    "                regex += splitter\n",
    "            else:\n",
    "                header = splitters[k].strip('<').strip('>')\n",
    "                regex += '(?P<%s>.*?)' % header\n",
    "                headers.append(header)\n",
    "        regex = re.compile('^' + regex + '$')\n",
    "        return headers, regex\n",
    "\n",
    "    def get_parameter_list(self, row):\n",
    "        template_regex = re.sub(r\"<.{1,5}>\", \"<*>\", row[\"EventTemplate\"])\n",
    "        if \"<*>\" not in template_regex: return []\n",
    "        template_regex = re.sub(r'([^A-Za-z0-9])', r'\\\\\\1', template_regex)\n",
    "        template_regex = re.sub(r'\\\\ +', r'\\s+', template_regex)\n",
    "        template_regex = \"^\" + template_regex.replace(\"\\<\\*\\>\", \"(.*?)\") + \"$\"\n",
    "        parameter_list = re.findall(template_regex, row[\"Content\"])\n",
    "        parameter_list = parameter_list[0] if parameter_list else ()\n",
    "        parameter_list = list(parameter_list) if isinstance(parameter_list, tuple) else [parameter_list]\n",
    "        return parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98335977",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir  = 'C:/Users/Anh Pham/HDFS/'  # The input directory of log file\n",
    "output_dir = 'Drain_result/'  # The output directory of parsing results\n",
    "log_file   = 'HDFS_2k.log'  # The input log file name\n",
    "log_format = '<Date> <Time> <Pid> <Level> <Component>: <Content>'  # HDFS log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression list for optional preprocessing (default: [])\n",
    "regex      = [\n",
    "    r'blk_(|-)[0-9]+' , # block id\n",
    "    r'(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)', # IP\n",
    "    r'(?<=[^A-Za-z0-9])(\\-?\\+?\\d+)(?=[^A-Za-z0-9])|[0-9]+$', # Numbers\n",
    "]\n",
    "st         = 0.5  # Similarity threshold\n",
    "depth      = 4  # Depth of all leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38714e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LogParser(log_format, indir=input_dir, outdir=output_dir,  depth=depth, st=st, rex=regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a2d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: C:/Users/Anh Pham/HDFS/HDFS_2k.log\n",
      "Processed 50.0% of log lines.\n",
      "Processed 100.0% of log lines.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "bad escape \\s at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\sre_parse.py:1041\u001b[0m, in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1041\u001b[0m     this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mchr\u001b[39m(\u001b[43mESCAPES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\s'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mLogParser.parse\u001b[1;34m(self, logName)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavePath):\n\u001b[0;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavePath)\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogCluL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParsing done. [Time taken: \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mLogParser.outputResult\u001b[1;34m(self, logClustL)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventTemplate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m log_templates\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_para:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_log[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameterList\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameter_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_log\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavePath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_structured.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m occ_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventTemplate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8839\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8828\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8830\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   8831\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8832\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8837\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   8838\u001b[0m )\n\u001b[1;32m-> 8839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mLogParser.get_parameter_list\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<*>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m template_regex: \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m    307\u001b[0m template_regex \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([^A-Za-z0-9])\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, template_regex)\n\u001b[1;32m--> 308\u001b[0m template_regex \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m +\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_regex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m template_regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m template_regex\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m parameter_list \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(template_regex, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:327\u001b[0m, in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subx\u001b[39m(pattern, template):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# internal: Pattern.sub/subn implementation helper\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[43m_compile_repl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m template[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(template[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;66;03m# literal replacement\u001b[39;00m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m template[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:318\u001b[0m, in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(_MAXCACHE)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_repl\u001b[39m(repl, pattern):\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# internal: compile replacement pattern\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msre_parse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\sre_parse.py:1044\u001b[0m, in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ASCIILETTERS:\n\u001b[1;32m-> 1044\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m s\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m this, \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[0;32m   1045\u001b[0m         lappend(this)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\s at position 0"
     ]
    }
   ],
   "source": [
    "parser.parse(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b12e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
